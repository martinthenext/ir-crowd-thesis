---
title: "Accuracy comparison at 1 vote per document"
output: 
  html_document: 
    keep_md: yes
---

Reading accuracy levels for different methods from a `tsv` file.

```{r}

read.accuracy.df <- function(filename, na.rm=TRUE) {
  accuracy <- read.delim(filename, header=FALSE)
  names(accuracy) <- c("Method", "Topic", "Accuracy")

  if (na.rm) {
    accuracy <- accuracy[!is.na(accuracy$Accuracy), ]
  }
  
  accuracy$Topic <- as.factor(accuracy$Topic)
  row.names(accuracy) <- NULL
  accuracy
}

accuracy <- read.accuracy.df("exp-accuracy-1-vote-per-doc.tsv")

nrow(accuracy)

head(accuracy)

```

Calculate mean accuracies:

```{r}

means <- aggregate(Accuracy ~ Method + Topic, accuracy, mean)

```

Let us print a star in front of a best method for a topic

```{r results='asis'}
library(knitr)

means <- cbind(means, Best="")
means$Best <- as.character(means$Best)
for (i in 1:nrow(means)) {
  current <- means[i, "Accuracy"]
  accuracies.on.this.topic <- means[means$Topic == means[i, "Topic"], "Accuracy"]
  max.accuracy <- max(accuracies.on.this.topic)
  if (current == max.accuracy) {
    means[i, "Best"] <- '*'
  }
}

kable(means, format="markdown")

```

List best methods for topics:

```{r results='asis'}

best.methods <- means[means$Best == '*', c("Topic", "Method")]

row.names(best.methods) <- NULL
kable(best.methods, format="markdown")

```

Total results

```{r}

counts <- table(best.methods$Method)
counts <- counts[counts!=0]
counts <- counts[order(counts, decreasing=TRUE)]
counts

```
